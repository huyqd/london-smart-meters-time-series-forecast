{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from utilsforecast.plotting import plot_series\n",
    "from statsforecast import StatsForecast\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.losses import *\n",
    "from statsmodels.tsa.seasonal import STL, seasonal_decompose, MSTL\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from tsfeatures import tsfeatures, stl_features\n",
    "\n",
    "from utilsforecast.losses import *\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from utilsforecast.feature_engineering import fourier, pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from functools import partial\n",
    "from plotting_utils import (\n",
    "    plotly_series as plot_series,\n",
    "    plot_decomposition,\n",
    "    plot_residuals_diagnostic,\n",
    ")\n",
    "from summary_utils import get_fitted_residuals\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\n",
    "    \"data/london_smart_meters/preprocessed/london_smart_meters_merged_block_0-7.parquet\"\n",
    ")\n",
    "timestamp = data.group_by(\"LCLid\").agg(\n",
    "    pl.datetime_range(\n",
    "        start=pl.col(\"start_timestamp\"),\n",
    "        end=pl.col(\"start_timestamp\").dt.offset_by(\n",
    "            pl.format(\"{}m\", pl.col(\"series_length\").sub(1).mul(30))\n",
    "        ),\n",
    "        interval=\"30m\",\n",
    "    ).alias(\"ds\"),\n",
    ")\n",
    "data = timestamp.join(data, on=\"LCLid\", how=\"inner\").rename(\n",
    "    {\"LCLid\": \"unique_id\", \"energy_consumption\": \"y\"}\n",
    ")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf22c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = \"unique_id\"\n",
    "time_ = \"ds\"\n",
    "target_ = \"y\"\n",
    "id_col = pl.col(id_)\n",
    "time_col = pl.col(time_)\n",
    "target_col = pl.col(target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f041ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data.filter(pl.col(\"file\").eq(\"block_7\"))\n",
    "    .select(\n",
    "        [\n",
    "            time_,\n",
    "            id_,\n",
    "            target_,\n",
    "            \"Acorn\",\n",
    "            \"Acorn_grouped\",\n",
    "            \"holidays\",\n",
    "            \"visibility\",\n",
    "            \"windBearing\",\n",
    "            \"temperature\",\n",
    "            \"dewPoint\",\n",
    "            \"pressure\",\n",
    "            \"apparentTemperature\",\n",
    "            \"windSpeed\",\n",
    "            \"precipType\",\n",
    "            \"icon\",\n",
    "            \"humidity\",\n",
    "            \"summary\",\n",
    "        ]\n",
    "    )\n",
    "    .explode(\n",
    "        [\n",
    "            time_,\n",
    "            target_,\n",
    "            \"holidays\",\n",
    "            \"visibility\",\n",
    "            \"windBearing\",\n",
    "            \"temperature\",\n",
    "            \"dewPoint\",\n",
    "            \"pressure\",\n",
    "            \"apparentTemperature\",\n",
    "            \"windSpeed\",\n",
    "            \"precipType\",\n",
    "            \"icon\",\n",
    "            \"humidity\",\n",
    "            \"summary\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee23d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_id = \"MAC000193\"\n",
    "data = data.filter(pl.col(id_).eq(selected_id))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941ff9d",
   "metadata": {},
   "source": [
    "## Baseline Forecasts in Time Series\n",
    "\n",
    "Baseline forecasts are simple, interpretable models that serve as reference points for evaluating more complex forecasting methods. They help us understand whether sophisticated models truly add value, or if simple heuristics are sufficient for the problem at hand. In practice, a good forecasting workflow always starts with strong baselines.\n",
    "\n",
    "Below are some common baseline models used in time series forecasting, along with their mathematical formulations:\n",
    "\n",
    "### 1. Naive Forecast\n",
    "\n",
    "The naive forecast assumes that the next value in the series will be the same as the last observed value.\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = y_t\n",
    "$$\n",
    "\n",
    "This approach is especially effective for random walk or highly persistent series.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Historic Average\n",
    "\n",
    "The historic average predicts the next value as the mean of all observed values up to the current time.\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = \\frac{1}{t} \\sum_{i=1}^{t} y_i\n",
    "$$\n",
    "\n",
    "This method works well for stationary series without strong trends or seasonality.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Seasonal Naive\n",
    "\n",
    "The seasonal naive forecast repeats the value from the same season in the previous cycle. For example, with half-hourly data and daily seasonality ($s=48$):\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = y_{t+1-s}\n",
    "$$\n",
    "\n",
    "where $s$ is the season length (here, $s=48$ for daily seasonality).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Drift Forecast\n",
    "\n",
    "This model extends the naive forecast by adding a constant drift (trend) term, estimated from the historical average change.\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = y_t + \\hat{d}\n",
    "$$\n",
    "\n",
    "where the drift $\\hat{d}$ is typically estimated as:\n",
    "\n",
    "$$\n",
    "\\hat{d} = \\frac{y_t - y_1}{t-1}\n",
    "$$\n",
    "\n",
    "#### Derivation\n",
    "\n",
    "Suppose we have a time series $\\{y_1, y_2, \\ldots, y_t\\}$.\n",
    "\n",
    "The random walk with drift model is:\n",
    "$$\n",
    "y_{k+1} = y_k + d\n",
    "$$\n",
    "where $d$ is the drift (constant increment), and $\\varepsilon_{k+1}$ is a noise term.\n",
    "\n",
    "If we recursively expand this from $y_1$:\n",
    "$$\n",
    "y_2 = y_1 + d \\\\\n",
    "y_3 = y_2 + d = y_1 + 2d \\\\\n",
    "\\vdots \\\\\n",
    "y_t = y_1 + (t-1)d + \n",
    "$$\n",
    "\n",
    "This means\n",
    "$$\n",
    "d = \\frac{y_t - y_1}{t-1}\n",
    "$$\n",
    "\n",
    "So the value at time $k$ is:\n",
    "$$\n",
    "y_k = y_1 + (k-1)\\frac{y_t - y_1}{t-1}\n",
    "$$\n",
    "\n",
    "This is the equation of a straight line passing through $(1, y_1)$ and $(t, y_t)$, showing that the random walk with drift essentially fits a line between the first and last points of the series.\n",
    "\n",
    "This means the forecast advances along a line defined by the starting and ending values, without considering any intermediate fluctuations or seasonality. It provides a simple way to capture a linear trend in the data.\n",
    "\n",
    "Hence, it is useful for series with a linear trend.\n",
    "\n",
    "---\n",
    "By comparing advanced models to these baselines, we can better assess the value added by more complex approaches. If a sophisticated model does not outperform these simple baselines, it may not be worth the extra complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713888f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import (\n",
    "    Naive,\n",
    "    SeasonalNaive,\n",
    "    HistoricAverage,\n",
    "    RandomWalkWithDrift,\n",
    ")\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    models=[\n",
    "        Naive(),\n",
    "        HistoricAverage(),\n",
    "        SeasonalNaive(season_length=48, alias=\"DailySeasonalNaive\"),\n",
    "        SeasonalNaive(season_length=48 * 7, alias=\"WeeklySeasonalNaive\"),\n",
    "        RandomWalkWithDrift(),\n",
    "    ],\n",
    "    freq=\"30m\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = fcst.cross_validation(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    fitted=True,\n",
    "    h=48,\n",
    "    n_windows=1,\n",
    "    step_size=48,\n",
    ").drop(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206932f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(data, y_hat, max_insample_length=200, width=1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48965a1a",
   "metadata": {},
   "source": [
    "Electricity load demand data typically exhibits strong seasonality with no trend. As a result, simple baseline methods such as the naive forecast, historic average, and drift are not well-suited for this type of data\n",
    "\n",
    "In contrast, models that explicitly account for seasonality, such as the daily and weekly seasonal naive methods, perform significantly better. Among these, the weekly seasonal naive model tends to track the actual time series more closely, as it leverages the repeated weekly consumption patterns inherent in electricity demand data. This highlights the importance of incorporating seasonality into forecasting models for load demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461b27f",
   "metadata": {},
   "source": [
    "### Model Validation Metrics\n",
    "\n",
    "To evaluate and compare forecasting models, we use several standard error metrics. Each metric provides a different perspective on model performance:\n",
    "\n",
    "#### 1. Mean Absolute Error (MAE)\n",
    "Measures the average magnitude of errors in the forecasts, without considering their direction.\n",
    "\n",
    "$$\n",
    "\\mathrm{MAE} = \\frac{1}{n} \\sum_{t=1}^n |y_t - \\hat{y}_t|\n",
    "$$\n",
    "\n",
    "- **Interpretation:** Lower MAE indicates better accuracy. It is easy to interpret but does not penalize large errors more than small ones.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Mean Squared Error (MSE)\n",
    "Calculates the average of the squared differences between actual and predicted values.\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE} = \\frac{1}{n} \\sum_{t=1}^n (y_t - \\hat{y}_t)^2\n",
    "$$\n",
    "\n",
    "- **Interpretation:** Penalizes larger errors more heavily. Useful when large errors are particularly undesirable.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Root Mean Squared Error (RMSE)\n",
    "The square root of MSE, bringing the error metric back to the original scale of the data.\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE} = \\sqrt{\\mathrm{MSE}}\n",
    "$$\n",
    "\n",
    "- **Interpretation:** Like MSE, but easier to interpret since it is in the same units as the data.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Mean Absolute Percentage Error (MAPE)\n",
    "Expresses forecast error as a percentage of the actual values.\n",
    "\n",
    "$$\n",
    "\\mathrm{MAPE} = \\frac{100\\%}{n} \\sum_{t=1}^n \\left| \\frac{y_t - \\hat{y}_t}{y_t} \\right|\n",
    "$$\n",
    "\n",
    "- **Interpretation:** Useful for comparing forecast accuracy across series of different scales. Sensitive to zero or near-zero actual values.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Symmetric Mean Absolute Percentage Error (sMAPE)\n",
    "A variation of MAPE that treats over- and under-forecasts more symmetrically.\n",
    "\n",
    "$$\n",
    "\\mathrm{sMAPE} = \\frac{100\\%}{n} \\sum_{t=1}^n \\frac{|y_t - \\hat{y}_t|}{(|y_t| + |\\hat{y}_t|)/2}\n",
    "$$\n",
    "\n",
    "- **Interpretation:** Bounded between 0% and 200%. Less sensitive to outliers and zero values than MAPE.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Mean Absolute Scaled Error (MASE) with Seasonality 48\n",
    "Compares the forecast error to the average error of a naive seasonal forecast (here, with a seasonality of 48, e.g., daily for half-hourly data).\n",
    "\n",
    "$$\n",
    "\\mathrm{MASE} = \\frac{\\mathrm{MAE}}{\\frac{1}{n-s} \\sum_{t=s+1}^n |y_t - y_{t-s}|}\n",
    "$$\n",
    "\n",
    "- **Interpretation:** \n",
    "    - MASE < 1: Model outperforms the seasonal naive forecast.\n",
    "    - MASE > 1: Model is worse than the seasonal naive.\n",
    "    - Seasonality = 48 means the benchmark is the value from the same time on the previous day.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "- Use MAE and RMSE for absolute error measurement.\n",
    "- Use MAPE and sMAPE for relative error (percentage-based).\n",
    "- Use MASE to benchmark against a simple seasonal naive model, especially for seasonal data.  \n",
    "Combining these metrics gives a comprehensive view of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed639f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "metrics = [\n",
    "    mae,\n",
    "    mse,\n",
    "    rmse,\n",
    "    mape,\n",
    "    smape,\n",
    "    partial(mase, seasonality=48),\n",
    "]\n",
    "evaluate(\n",
    "    y_hat,\n",
    "    metrics=metrics,\n",
    "    train_df=data.select([id_, time_, target_]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c3a0e",
   "metadata": {},
   "source": [
    "The evaluation metrics confirm the visual findings from the plots: the naive, mean (historic average), and drift models yield relatively high error values, indicating poor performance on this dataset. This is expected, as these models do not account for the strong seasonality present in electricity load demand.\n",
    "\n",
    "In contrast, the weekly seasonal naive model achieves significantly lower errors across all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea91a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = fcst.forecast(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    h=48,\n",
    "    fitted=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417eca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_residuals = get_fitted_residuals(fcst).drop_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64063c",
   "metadata": {},
   "source": [
    "### Residual Analysis\n",
    "\n",
    "Residual analysis is a crucial step in time series modeling, as it helps assess whether the chosen model adequately captures the underlying patterns in the data. By examining the residuals—the differences between observed values and model predictions—we can check for remaining structure, autocorrelation, or non-randomness.\n",
    "\n",
    "Ideally, residuals should resemble white noise: they should be randomly distributed with constant variance and no discernible patterns over time. If residuals display autocorrelation, seasonality, or changing variance, this indicates that the model has not fully captured important aspects of the data, and further refinement or alternative modeling approaches may be necessary.\n",
    "\n",
    "Statistical tests, such as the Ljung-Box test, can formally assess whether residuals are uncorrelated. Visual diagnostics, including residual plots and autocorrelation plots, provide additional insights into model adequacy and potential improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"WeeklySeasonalNaive\"\n",
    "\n",
    "residuals = fitted_residuals.get_column(model).drop_nulls().to_numpy()\n",
    "time = fitted_residuals.get_column(time_).drop_nulls().to_numpy()\n",
    "\n",
    "plot_residuals_diagnostic(time=time, residuals=residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32b1d3",
   "metadata": {},
   "source": [
    "The residual plot reveals significant autocorrelation, indicating that the residuals are not white noise. This suggests that the model has not fully captured all the underlying patterns or dependencies in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d6d52",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "### Ljung-Box test\n",
    "The Ljung-Box test is a statistical test used to check whether any group of autocorrelations of a time series are significantly different from zero. In other words, it tests whether the residuals (errors) from a time series model are independently distributed (i.e., exhibit no autocorrelation).\n",
    "\n",
    "### Purpose\n",
    "\n",
    "- **Null hypothesis ($H_0$):** The data are independently distributed (no autocorrelation up to lag $h$).\n",
    "- **Alternative hypothesis ($H_1$):** The data are not independently distributed (there is autocorrelation at one or more lags up to $h$).\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "The Ljung-Box test statistic is calculated as:\n",
    "\n",
    "$$\n",
    "Q = n(n+2) \\sum_{k=1}^h \\frac{\\hat{\\rho}_k^2}{n-k}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $n$ = number of observations\n",
    "- $h$ = number of lags being tested\n",
    "- $\\hat{\\rho}_k$ = sample autocorrelation at lag $k$\n",
    "\n",
    "### Distribution\n",
    "\n",
    "- Under the null hypothesis, $Q$ approximately follows a chi-squared distribution with $h$ degrees of freedom:\n",
    "    $$\n",
    "    Q \\sim \\chi^2_h\n",
    "    $$\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Compute residuals** from your time series model.\n",
    "2. **Calculate sample autocorrelations** $\\hat{\\rho}_k$ for lags $k = 1, 2, ..., h$.\n",
    "3. **Compute $Q$** using the formula above.\n",
    "4. **Compare $Q$** to the critical value from the chi-squared distribution with $h$ degrees of freedom, or compute the p-value.\n",
    "5. **Decision:**  \n",
    "     - If the p-value is small (e.g., $< 0.05$), reject $H_0$ (there is significant autocorrelation).\n",
    "     - If the p-value is large, do not reject $H_0$ (no evidence of autocorrelation).\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Low p-value:** Residuals are autocorrelated; the model may be inadequate.\n",
    "- **High p-value:** No evidence of autocorrelation; residuals resemble white noise.\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 1    | Compute residuals from model |\n",
    "| 2    | Calculate autocorrelations up to lag $h$ |\n",
    "| 3    | Compute $Q$ statistic |\n",
    "| 4    | Compare $Q$ to $\\chi^2_h$ distribution |\n",
    "| 5    | Interpret p-value |\n",
    "\n",
    "The Ljung-Box test is widely used for model diagnostics in time series analysis to ensure that the model has captured all temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defea1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_test = acorr_ljungbox(residuals, boxpierce=True)\n",
    "resid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d8209",
   "metadata": {},
   "source": [
    "The Ljung-Box test result shows a p-value of 0, which means we reject the null hypothesis of no autocorrelation in the residuals. This indicates that significant autocorrelation remains, which is inline with what we observe in the ACF plot above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
