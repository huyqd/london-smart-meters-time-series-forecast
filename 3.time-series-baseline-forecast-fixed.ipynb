{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0a53dc",
   "metadata": {},
   "source": [
    "# Baseline Time Series Forecasting for Electricity Load Data\n",
    "\n",
    "This notebook demonstrates and evaluates several baseline time series forecasting models for electricity load data. Each section introduces a different model, explains its assumptions and suitability, and provides diagnostics to assess its performance. Baseline models are essential for benchmarking more complex forecasting approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72afd092",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We begin by importing all necessary libraries for data manipulation, modeling, plotting, and evaluation. This includes `polars` for efficient data handling, `numpy` for numerical operations, `plotly` for interactive visualization, and forecasting utilities from `statsforecast` and custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89370507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import polars as pl\n",
    "\n",
    "# Plotting\n",
    "\n",
    "# Forecasting models and utilities\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    Naive,\n",
    "    HistoricAverage,\n",
    "    SeasonalNaive,\n",
    "    RandomWalkWithDrift,\n",
    ")\n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "# Feature engineering and diagnostics\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Custom plotting and summary utilities\n",
    "from plotting_utils import (\n",
    "    plotly_series as plot_series,\n",
    "    plot_residuals_diagnostic,\n",
    ")\n",
    "from summary_utils import get_fitted_residuals\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be819501",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "We load the preprocessed electricity load dataset using `polars`. The dataset contains half-hourly energy consumption readings from London smart meters, along with weather and calendar features. We generate a timestamp column for each series and rename columns for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7765519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data = pl.read_parquet(\n",
    "    \"data/london_smart_meters/preprocessed/london_smart_meters_merged_block_0-7.parquet\"\n",
    ")\n",
    "\n",
    "# Generate timestamp column for each smart meter\n",
    "timestamp = data.group_by(\"LCLid\").agg(\n",
    "    pl.datetime_range(\n",
    "        start=pl.col(\"start_timestamp\"),\n",
    "        end=pl.col(\"start_timestamp\").dt.offset_by(\n",
    "            pl.format(\"{}m\", pl.col(\"series_length\").sub(1).mul(30))\n",
    "        ),\n",
    "        interval=\"30m\",\n",
    "    ).alias(\"ds\"),\n",
    ")\n",
    "\n",
    "# Join timestamps and rename columns for modeling\n",
    "data = timestamp.join(data, on=\"LCLid\", how=\"inner\").rename(\n",
    "    {\"LCLid\": \"unique_id\", \"energy_consumption\": \"y\"}\n",
    ")\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426dc846",
   "metadata": {},
   "source": [
    "## 3. Select a Single Time Series\n",
    "\n",
    "For demonstration, we focus on a single smart meter (e.g., `MAC000193`). This allows for clear visualization and comparison of model forecasts on a single, interpretable series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55849d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names for modeling\n",
    "id_ = \"unique_id\"\n",
    "time_ = \"ds\"\n",
    "target_ = \"y\"\n",
    "id_col = pl.col(id_)\n",
    "time_col = pl.col(time_)\n",
    "target_col = pl.col(target_)\n",
    "\n",
    "# Filter for a single block and select relevant columns\n",
    "data = (\n",
    "    data.filter(pl.col(\"file\").eq(\"block_7\"))\n",
    "    .select(\n",
    "        [\n",
    "            time_,\n",
    "            id_,\n",
    "            target_,\n",
    "            \"Acorn\",\n",
    "            \"Acorn_grouped\",\n",
    "            \"holidays\",\n",
    "            \"visibility\",\n",
    "            \"windBearing\",\n",
    "            \"temperature\",\n",
    "            \"dewPoint\",\n",
    "            \"pressure\",\n",
    "            \"apparentTemperature\",\n",
    "            \"windSpeed\",\n",
    "            \"precipType\",\n",
    "            \"icon\",\n",
    "            \"humidity\",\n",
    "            \"summary\",\n",
    "        ]\n",
    "    )\n",
    "    .explode(\n",
    "        [\n",
    "            time_,\n",
    "            target_,\n",
    "            \"holidays\",\n",
    "            \"visibility\",\n",
    "            \"windBearing\",\n",
    "            \"temperature\",\n",
    "            \"dewPoint\",\n",
    "            \"pressure\",\n",
    "            \"apparentTemperature\",\n",
    "            \"windSpeed\",\n",
    "            \"precipType\",\n",
    "            \"icon\",\n",
    "            \"humidity\",\n",
    "            \"summary\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Select a single smart meter for demonstration\n",
    "selected_id = \"MAC000193\"\n",
    "data = data.filter(pl.col(id_).eq(selected_id))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c75cc8",
   "metadata": {},
   "source": [
    "## 4. Naive Forecast Model\n",
    "\n",
    "The **Naive forecast** predicts the next value as the last observed value in the series:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = y_t\n",
    "$$\n",
    "\n",
    "This model is effective for random walk or highly persistent series, but it does not account for seasonality or trend. For electricity load data, which typically exhibits strong seasonality, the naive model often underperforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf71210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up StatsForecast with Naive model only\n",
    "fcst_naive = StatsForecast(\n",
    "    models=[Naive()],\n",
    "    freq=\"30m\",\n",
    ")\n",
    "\n",
    "# Forecast using the Naive model\n",
    "y_hat_naive = fcst_naive.cross_validation(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    fitted=True,\n",
    "    h=48,\n",
    "    n_windows=1,\n",
    "    step_size=48,\n",
    ").drop(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4490dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. all baseline forecasts\n",
    "plot_series(\n",
    "    data,\n",
    "    y_hat_naive,\n",
    "    max_insample_length=200,\n",
    "    width=1400,\n",
    "    title=\"Actual vs. Baseline Forecast for Electricity Load\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f132566",
   "metadata": {},
   "source": [
    "## 5. Historic Average Forecast Model\n",
    "\n",
    "The **Historic Average** model predicts the next value as the mean of all observed values up to the current time:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = \\frac{1}{t} \\sum_{i=1}^{t} y_i\n",
    "$$\n",
    "\n",
    "This approach is suitable for stationary series without strong trends or seasonality. However, electricity load data often has pronounced daily and weekly cycles, which this model cannot capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up StatsForecast with Historic Average model only\n",
    "fcst_mean = StatsForecast(\n",
    "    models=[HistoricAverage()],\n",
    "    freq=\"30m\",\n",
    ")\n",
    "\n",
    "# Forecast using the Historic Average model\n",
    "y_hat_mean = fcst_mean.cross_validation(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    fitted=True,\n",
    "    h=48,\n",
    "    n_windows=1,\n",
    "    step_size=48,\n",
    ").drop(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. all baseline forecasts\n",
    "plot_series(\n",
    "    data,\n",
    "    y_hat_mean,\n",
    "    max_insample_length=200,\n",
    "    width=1400,\n",
    "    title=\"Actual vs. Baseline Forecast for Electricity Load\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6366039",
   "metadata": {},
   "source": [
    "## 6. Seasonal Naive Forecast Models (Daily & Weekly)\n",
    "\n",
    "The **Seasonal Naive** model repeats the value from the same season in the previous cycle:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = y_{t+1-s}\n",
    "$$\n",
    "\n",
    "where $s$ is the season length (e.g., $s=48$ for daily, $s=336$ for weekly seasonality with half-hourly data).\n",
    "\n",
    "These models are well-suited for electricity load forecasting, as load patterns often repeat daily and weekly due to human activity and routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up StatsForecast with daily and weekly Seasonal Naive models\n",
    "fcst_seasonal = StatsForecast(\n",
    "    models=[\n",
    "        SeasonalNaive(season_length=48, alias=\"DailySeasonalNaive\"),\n",
    "        SeasonalNaive(season_length=48 * 7, alias=\"WeeklySeasonalNaive\"),\n",
    "    ],\n",
    "    freq=\"30m\",\n",
    ")\n",
    "\n",
    "# Forecast using the Seasonal Naive models\n",
    "y_hat_seasonal = fcst_seasonal.cross_validation(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    fitted=True,\n",
    "    h=48,\n",
    "    n_windows=1,\n",
    "    step_size=48,\n",
    ").drop(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. all baseline forecasts\n",
    "plot_series(\n",
    "    data,\n",
    "    y_hat_seasonal,\n",
    "    max_insample_length=200,\n",
    "    width=1400,\n",
    "    title=\"Actual vs. Baseline Forecast for Electricity Load\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a98b17",
   "metadata": {},
   "source": [
    "## 7. Drift Forecast Model\n",
    "\n",
    "The **Drift** model extends the naive forecast by adding a linear trend (drift) estimated from the historical average change:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = y_t + \\hat{d}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\hat{d} = \\frac{y_t - y_1}{t-1}\n",
    "$$\n",
    "\n",
    "#### Derivation\n",
    "\n",
    "Suppose we have a time series $\\{y_1, y_2, \\ldots, y_t\\}$.\n",
    "\n",
    "The random walk with drift model is:\n",
    "$$\n",
    "y_{k+1} = y_k + d\n",
    "$$\n",
    "where $d$ is the drift (constant increment), and $\\varepsilon_{k+1}$ is a noise term.\n",
    "\n",
    "If we recursively expand this from $y_1$:\n",
    "$$\n",
    "y_2 = y_1 + d \\\\\n",
    "y_3 = y_2 + d = y_1 + 2d \\\\\n",
    "\\vdots \\\\\n",
    "y_t = y_1 + (t-1)d + \n",
    "$$\n",
    "\n",
    "This means\n",
    "$$\n",
    "d = \\frac{y_t - y_1}{t-1}\n",
    "$$\n",
    "\n",
    "So the value at time $k$ is:\n",
    "$$\n",
    "y_k = y_1 + (k-1)\\frac{y_t - y_1}{t-1}\n",
    "$$\n",
    "\n",
    "This is the equation of a straight line passing through $(1, y_1)$ and $(t, y_t)$, showing that the random walk with drift essentially fits a line between the first and last points of the series.\n",
    "\n",
    "This means the forecast advances along a line defined by the starting and ending values, without considering any intermediate fluctuations or seasonality. It provides a simple way to capture a linear trend in the data.\n",
    "\n",
    "Hence, this model is appropriate for series with a linear trend. However, electricity load data is typically dominated by seasonality rather than trend, so the drift model may not perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435dd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up StatsForecast with Random Walk with Drift model only\n",
    "fcst_drift = StatsForecast(\n",
    "    models=[RandomWalkWithDrift()],\n",
    "    freq=\"30m\",\n",
    ")\n",
    "\n",
    "# Forecast using the Drift model\n",
    "y_hat_drift = fcst_drift.cross_validation(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    fitted=True,\n",
    "    h=48,\n",
    "    n_windows=1,\n",
    "    step_size=48,\n",
    ").drop(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. all baseline forecasts\n",
    "plot_series(\n",
    "    data,\n",
    "    y_hat_drift,\n",
    "    max_insample_length=200,\n",
    "    width=1400,\n",
    "    title=\"Actual vs. Baseline Forecast for Electricity Load\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4e849",
   "metadata": {},
   "source": [
    "Electricity load demand data typically exhibits strong seasonality with no trend. As a result, simple baseline methods such as the naive forecast, historic average, and drift are not well-suited for this type of data\n",
    "\n",
    "In contrast, models that explicitly account for seasonality, such as the daily and weekly seasonal naive methods, perform significantly better. Among these, the weekly seasonal naive model tends to track the actual time series more closely, as it leverages the repeated weekly consumption patterns inherent in electricity demand data. This highlights the importance of incorporating seasonality into forecasting models for load demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f522442",
   "metadata": {},
   "source": [
    "## 8. Evaluate Forecast Accuracy with Metrics\n",
    "\n",
    "To quantitatively compare model performance, we compute standard forecast accuracy metrics:\n",
    "\n",
    "- **MAE** (Mean Absolute Error):  \n",
    "    $$\n",
    "    \\mathrm{MAE} = \\frac{1}{n} \\sum_{t=1}^n |y_t - \\hat{y}_t|\n",
    "    $$\n",
    "    *Pros*: Simple to interpret, not sensitive to outliers.  \n",
    "    *Cons*: Does not penalize large errors more than small ones.  \n",
    "    *Suitability*: Good for electricity load data, especially when all errors are equally important.\n",
    "\n",
    "- **MSE** (Mean Squared Error):  \n",
    "    $$\n",
    "    \\mathrm{MSE} = \\frac{1}{n} \\sum_{t=1}^n (y_t - \\hat{y}_t)^2\n",
    "    $$\n",
    "    *Pros*: Penalizes larger errors more heavily, useful for highlighting large deviations.  \n",
    "    *Cons*: Sensitive to outliers, units are squared.  \n",
    "    *Suitability*: Useful for electricity load forecasting when large errors are particularly undesirable.\n",
    "\n",
    "- **RMSE** (Root Mean Squared Error):  \n",
    "    $$\n",
    "    \\mathrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{t=1}^n (y_t - \\hat{y}_t)^2}\n",
    "    $$\n",
    "    *Pros*: Same units as the original data, interpretable.  \n",
    "    *Cons*: Still sensitive to outliers.  \n",
    "    *Suitability*: Commonly used in load forecasting, especially when large errors are costly.\n",
    "\n",
    "- **MAPE** (Mean Absolute Percentage Error):  \n",
    "    $$\n",
    "    \\mathrm{MAPE} = \\frac{100\\%}{n} \\sum_{t=1}^n \\left| \\frac{y_t - \\hat{y}_t}{y_t} \\right|\n",
    "    $$\n",
    "    *Pros*: Scale-independent, easy to interpret as a percentage.  \n",
    "    *Cons*: Undefined or infinite when $y_t = 0$, can be biased when actual values are near zero.  \n",
    "    *Suitability*: Useful for electricity load data with consistently positive values, but caution needed if zeros are present.\n",
    "\n",
    "- **sMAPE** (Symmetric Mean Absolute Percentage Error):  \n",
    "    $$\n",
    "    \\mathrm{sMAPE} = \\frac{100\\%}{n} \\sum_{t=1}^n \\frac{|y_t - \\hat{y}_t|}{(|y_t| + |\\hat{y}_t|)/2}\n",
    "    $$\n",
    "    *Pros*: Bounded between 0% and 200%, less sensitive to scale and zeros than MAPE.  \n",
    "    *Cons*: Can still be unstable when both $y_t$ and $\\hat{y}_t$ are near zero.  \n",
    "    *Suitability*: Preferred over MAPE for electricity load forecasting, especially with low or zero values.\n",
    "\n",
    "- **MASE** (Mean Absolute Scaled Error, with seasonality $s=48$):  \n",
    "    $$\n",
    "    \\mathrm{MASE} = \\frac{\\frac{1}{n} \\sum_{t=1}^n |y_t - \\hat{y}_t|}{\\frac{1}{n-s} \\sum_{t=s+1}^n |y_t - y_{t-s}|}\n",
    "    $$\n",
    "    *Pros*: Scale-free, interpretable relative to a seasonal naive forecast, robust to scale and seasonality.  \n",
    "    *Cons*: Requires enough data to compute seasonal differences.  \n",
    "    *Suitability*: Highly recommended for electricity load data, as it benchmarks models against a simple seasonal naive baseline (e.g., daily seasonality for half-hourly data).\n",
    "\n",
    "These metrics provide different perspectives on forecast accuracy. For electricity load data, MASE (with daily seasonality) is especially informative, as it benchmarks models against a simple seasonal naive forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "y_hat_all = pl.concat(\n",
    "    [y_hat_mean, y_hat_naive, y_hat_seasonal, y_hat_drift], how=\"align\"\n",
    ")\n",
    "metrics = [\n",
    "    mae,\n",
    "    mse,\n",
    "    rmse,\n",
    "    mape,\n",
    "    smape,\n",
    "    partial(mase, seasonality=48),\n",
    "]\n",
    "\n",
    "# Evaluate all baseline forecasts\n",
    "evaluate(\n",
    "    y_hat_all,\n",
    "    metrics=metrics,\n",
    "    train_df=data.select([id_, time_, target_]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cefd1f",
   "metadata": {},
   "source": [
    "The evaluation metrics confirm the visual findings from the plots: the naive, mean (historic average), and drift models yield relatively high error values, indicating poor performance on this dataset. This is expected, as these models do not account for the strong seasonality present in electricity load demand.\n",
    "\n",
    "In contrast, the weekly seasonal naive model achieves significantly lower errors across all metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a59088",
   "metadata": {},
   "source": [
    "## 10. Residual Analysis for Baseline Models\n",
    "\n",
    "Residual analysis is a crucial step in time series modeling, as it helps assess whether the chosen model adequately captures the underlying patterns in the data. By examining the residuals—the differences between observed values and model predictions—we can check for remaining structure, autocorrelation, or non-randomness.\n",
    "\n",
    "Ideally, residuals should resemble white noise: they should be randomly distributed with constant variance and no discernible patterns over time. If residuals display autocorrelation, seasonality, or changing variance, this indicates that the model has not fully captured important aspects of the data, and further refinement or alternative modeling approaches may be necessary.\n",
    "\n",
    "Here, we analyze the residuals (forecast errors) of the best-performing baseline model (typically the Weekly Seasonal Naive for electricity load)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = fcst_seasonal.forecast(\n",
    "    df=data.select([id_, time_, target_col.forward_fill()]),\n",
    "    h=48,\n",
    "    fitted=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_residuals = get_fitted_residuals(fcst_seasonal).drop_nans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fitted residuals for the Weekly Seasonal Naive model\n",
    "fitted_residuals = get_fitted_residuals(fcst_seasonal).drop_nans()\n",
    "model = \"WeeklySeasonalNaive\"\n",
    "\n",
    "residuals = fitted_residuals.get_column(model).drop_nulls().to_numpy()\n",
    "time = fitted_residuals.get_column(time_).drop_nulls().to_numpy()\n",
    "\n",
    "# Plot residual diagnostics\n",
    "plot_residuals_diagnostic(time=time, residuals=residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536fd4a",
   "metadata": {},
   "source": [
    "The residual plot reveals significant autocorrelation, indicating that the residuals are not white noise. This suggests that the model has not fully captured all the underlying patterns or dependencies in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b0ea6",
   "metadata": {},
   "source": [
    "## 11. Ljung-Box Test for Residual Autocorrelation\n",
    "The Ljung-Box test is a statistical test used to check whether any group of autocorrelations of a time series are significantly different from zero. In other words, it tests whether the residuals (errors) from a time series model are independently distributed (i.e., exhibit no autocorrelation).\n",
    "\n",
    "### Purpose\n",
    "\n",
    "- **Null hypothesis ($H_0$):** The data are independently distributed (no autocorrelation up to lag $h$).\n",
    "- **Alternative hypothesis ($H_1$):** The data are not independently distributed (there is autocorrelation at one or more lags up to $h$).\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "The Ljung-Box test statistic is calculated as:\n",
    "\n",
    "$$\n",
    "Q = n(n+2) \\sum_{k=1}^h \\frac{\\hat{\\rho}_k^2}{n-k}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $n$ = number of observations\n",
    "- $h$ = number of lags being tested\n",
    "- $\\hat{\\rho}_k$ = sample autocorrelation at lag $k$\n",
    "\n",
    "### Distribution\n",
    "\n",
    "- Under the null hypothesis, $Q$ approximately follows a chi-squared distribution with $h$ degrees of freedom:\n",
    "    $$\n",
    "    Q \\sim \\chi^2_h\n",
    "    $$\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Compute residuals** from your time series model.\n",
    "2. **Calculate sample autocorrelations** $\\hat{\\rho}_k$ for lags $k = 1, 2, ..., h$.\n",
    "3. **Compute $Q$** using the formula above.\n",
    "4. **Compare $Q$** to the critical value from the chi-squared distribution with $h$ degrees of freedom, or compute the p-value.\n",
    "5. **Decision:**  \n",
    "     - If the p-value is small (e.g., $< 0.05$), reject $H_0$ (there is significant autocorrelation).\n",
    "     - If the p-value is large, do not reject $H_0$ (no evidence of autocorrelation).\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Low p-value:** Residuals are autocorrelated; the model may be inadequate.\n",
    "- **High p-value:** No evidence of autocorrelation; residuals resemble white noise.\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 1    | Compute residuals from model |\n",
    "| 2    | Calculate autocorrelations up to lag $h$ |\n",
    "| 3    | Compute $Q$ statistic |\n",
    "| 4    | Compare $Q$ to $\\chi^2_h$ distribution |\n",
    "| 5    | Interpret p-value |\n",
    "\n",
    "The Ljung-Box test is widely used for model diagnostics in time series analysis to ensure that the model has captured all temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Ljung-Box test to residuals\n",
    "resid_test = acorr_ljungbox(residuals, boxpierce=True)\n",
    "resid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdc915",
   "metadata": {},
   "source": [
    "The Ljung-Box test result shows a p-value of 0, which means we reject the null hypothesis of no autocorrelation in the residuals. This indicates that significant autocorrelation remains, which is inline with what we observe in the ACF plot above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
