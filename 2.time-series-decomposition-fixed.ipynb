{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0098c42",
   "metadata": {},
   "source": [
    "# Time Series Decomposition: Understanding Electricity Load Patterns\n",
    "\n",
    "In this notebook, we’ll explore how to break down (decompose) a household electricity time series into its fundamental components: **trend**, **seasonality**, and **residuals**. We’ll use several decomposition methods, discuss their strengths and limitations, and learn how to interpret the results. This is a crucial step for anyone learning time series analysis or building forecasting models.\n",
    "\n",
    "All explanations are written for beginners and are suitable for documenting your learning journey as a blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82bacf",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We’ll use `polars` for fast data handling, `plotly` for interactive plots, and several time series decomposition tools from `statsmodels` and `utilsforecast`. Some code is for plotting and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f21e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from statsmodels.tsa.seasonal import STL, seasonal_decompose, MSTL\n",
    "from tsfeatures import tsfeatures, stl_features\n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.feature_engineering import fourier, pipeline\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from functools import partial\n",
    "from plotting_utils import (\n",
    "    plotly_series as plot_series,\n",
    "    plot_decomposition,\n",
    ")\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd30644",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Data\n",
    "\n",
    "We’ll use half-hourly electricity consumption data for a single household. This keeps things simple and lets us focus on the decomposition methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d6a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\n",
    "    \"data/london_smart_meters/preprocessed/london_smart_meters_merged_block_0-7.parquet\"\n",
    ")\n",
    "timestamp = data.group_by(\"LCLid\").agg(\n",
    "    pl.datetime_range(\n",
    "        start=pl.col(\"start_timestamp\"),\n",
    "        end=pl.col(\"start_timestamp\").dt.offset_by(\n",
    "            pl.format(\"{}m\", pl.col(\"series_length\").sub(1).mul(30))\n",
    "        ),\n",
    "        interval=\"30m\",\n",
    "    ).alias(\"ds\"),\n",
    ")\n",
    "data = timestamp.join(data, on=\"LCLid\", how=\"inner\").rename(\n",
    "    {\"LCLid\": \"unique_id\", \"energy_consumption\": \"y\"}\n",
    ")\n",
    "data = data.filter(pl.col(\"file\").eq(\"block_7\"))\n",
    "id_ = \"unique_id\"\n",
    "time_ = \"ds\"\n",
    "target_ = \"y\"\n",
    "data = data.select([time_, id_, target_]).explode([time_, target_])\n",
    "selected_id = \"MAC000193\"\n",
    "data = data.filter(pl.col(id_).eq(selected_id))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceee449",
   "metadata": {},
   "source": [
    "## 3. Visualize the Time Series\n",
    "\n",
    "Let’s plot the raw time series to get a sense of its structure before decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31852f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(data, max_insample_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbe8a5",
   "metadata": {},
   "source": [
    "## 4. Traditional Seasonal Decomposition\n",
    "\n",
    "We start with the classic approach: decompose the series into **trend**, **seasonality**, and **residuals** using moving averages and period averages. This is a great way to build intuition for what decomposition means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6f054",
   "metadata": {},
   "source": [
    "Seasonal decomposition is a fundamental technique in time series analysis that separates a time series into three main components:\n",
    "1. **Trend**: The long-term progression of the series, representing the underlying direction.\n",
    "2. **Seasonality**: The repeating patterns or cycles within a fixed period.\n",
    "3. **Residual**: The remaining variation after removing the trend and seasonality, often referred to as noise or irregularity.\n",
    "\n",
    "This decomposition can be expressed mathematically as:\n",
    "- **Additive Model**: $y_t = T_t + S_t + R_t$\n",
    "- **Multiplicative Model**: $y_t = T_t \\times S_t \\times R_t$\n",
    "\n",
    "Here, $y_t$ is the observed value at time $ t $, $ T_t $ is the trend component, $ S_t $ is the seasonal component, and $ R_t $ is the residual component.\n",
    "\n",
    "#### 1. Extracting the Trend Component\n",
    "The trend component $ T_t $ is typically estimated using a **moving average**. A moving average smooths the time series by averaging values over a fixed window, helping to remove short-term fluctuations and highlight the long-term trend.\n",
    "\n",
    "For a centered moving average with a window size $ k $, the trend at time $ t $ is computed as:\n",
    "$$\n",
    "T_t = \\frac{1}{k} \\sum_{i=-\\frac{k-1}{2}}^{\\frac{k-1}{2}} y_{t+i}\n",
    "$$\n",
    "Here, $ k $ is often chosen to match the periodicity of the data (e.g., 12 for monthly data with yearly seasonality).\n",
    "\n",
    "For example, if the data has a daily seasonality with 48 half-hourly observations per day, a moving average with a window size of 48 can be used to compute the trend.\n",
    "\n",
    "#### 2. Extracting the Seasonal Component\n",
    "Once the trend $ T_t $ is estimated, the seasonal component $ S_t $ can be computed by removing the trend from the original series and averaging the detrended values for each period.\n",
    "\n",
    "For an additive model:\n",
    "$$\n",
    "S_t = \\frac{1}{n} \\sum_{j=1}^{n} (y_{t+jp} - T_{t+jp})\n",
    "$$\n",
    "For a multiplicative model:\n",
    "$$\n",
    "S_t = \\frac{1}{n} \\sum_{j=1}^{n} \\frac{y_{t+jp}}{T_{t+jp}}\n",
    "$$\n",
    "Here, $ p $ is the period of seasonality (e.g., 48 for daily seasonality), and $ n $ is the number of complete cycles in the data.\n",
    "\n",
    "The seasonal component is computed separately for each time point within the period (e.g., for each half-hour in a day), and the resulting seasonal values are repeated across the entire time series.\n",
    "\n",
    "#### 3. Computing the Residual Component\n",
    "Finally, the residual component $ R_t $ is obtained by subtracting the trend and seasonal components from the original series:\n",
    "- For an additive model: $ R_t = y_t - T_t - S_t $\n",
    "- For a multiplicative model: $ R_t = \\frac{y_t}{T_t \\times S_t} $\n",
    "\n",
    "#### Full Workflow\n",
    "1. Compute the trend using a moving average.\n",
    "2. Subtract the trend from the original series to get the detrended series.\n",
    "3. Compute the seasonal component by averaging the detrended values for each period.\n",
    "4. Subtract the trend and seasonal components from the original series to get the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = seasonal_decompose(\n",
    "    data.select(pl.col(target_).forward_fill()),\n",
    "    period=48,  # daily seasonality for half-hourly data\n",
    "    model=\"additive\",\n",
    "    extrapolate_trend=\"freq\",\n",
    "    filt=np.repeat(1 / (30 * 48), 30 * 48),\n",
    ")\n",
    "time = data.get_column(time_).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_decomposition(\n",
    "    time,\n",
    "    res.observed,\n",
    "    res.seasonal,\n",
    "    res.trend,\n",
    "    res.resid,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f0aa5",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- **Flat Trend:** The trend is essentially flat, as expected for a single household.\n",
    "- **Seasonality:** Strong daily cycles are visible.\n",
    "- **Residuals:** Still show some structure, suggesting more complex seasonality or patterns remain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145516a7",
   "metadata": {},
   "source": [
    "This traditional decomposition method is simple yet powerful for understanding the structure of a time series. However, there are some caveats with this method when it comes to computing trend and seasonality\n",
    "\n",
    "#### Caveats of Using Moving Average for Trend Extraction\n",
    "\n",
    "While moving average is simple and intuitive, it has several limitations:\n",
    "\n",
    "- **Edge Effects**: The moving average cannot be computed at the start and end of the series, leading to missing values at the boundaries.\n",
    "- **Fixed Window**: It uses a fixed window size, which may not adapt well to changes in the trend or to non-stationary data.\n",
    "- **Inflexibility**: It cannot capture non-linear or rapidly changing trends, as it only smooths over a fixed interval.\n",
    "- **Sensitivity to Outliers**: Moving averages can be influenced by outliers within the window, distorting the estimated trend.\n",
    "\n",
    "#### Caveats of Seasonality Computation in Simple Seasonal Decomposition\n",
    "\n",
    "- **Assumes Constant Seasonality**: The method assumes the seasonal pattern is fixed and repeats identically in every cycle, which may not be true for real-world data where seasonality can evolve over time.\n",
    "- **Sensitive to Outliers and Missing Data**: Outliers or missing values in the detrended series can distort the estimated seasonal pattern, as the seasonal component is computed by averaging across periods.\n",
    "- **Requires Complete Cycles**: Accurate seasonal estimation depends on having a sufficient number of complete seasonal cycles; otherwise, the seasonal averages may be biased.\n",
    "- **Ignores Multiple or Changing Seasonalities**: Simple decomposition cannot handle multiple overlapping seasonal patterns or seasonality that changes in strength or shape over time. Advanced methods like STL or MSTL are needed for such cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.select(pl.col(target_).forward_fill()).to_numpy().squeeze()\n",
    "# Compute trend using moving average with window size equal to period (48 for daily seasonality)\n",
    "window = 48\n",
    "trend = np.convolve(y, np.ones(window) / window, mode=\"same\")\n",
    "\n",
    "detrended = y - trend\n",
    "period = 48\n",
    "period_averages = np.array([np.nanmean(detrended[i::period]) for i in range(period)])\n",
    "period_averages -= np.mean(period_averages)\n",
    "\n",
    "seasonal = np.tile(period_averages, len(detrended) // period + 1)[: len(detrended)]\n",
    "\n",
    "residual = y - trend - seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decomposition(\n",
    "    time=time,\n",
    "    observed=y,\n",
    "    trend=trend,\n",
    "    seasonal=seasonal,\n",
    "    resid=residual,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d513d9",
   "metadata": {},
   "source": [
    "#### When to Use Seasonally Adjusted Data vs. Extracted Seasonal Components\n",
    "\n",
    "**Seasonally adjusted data** is obtained by removing the estimated seasonal component from the original time series. This is useful when you want to analyze or model the underlying trend and irregular fluctuations without the influence of recurring seasonal patterns. Typical use cases include:\n",
    "\n",
    "- **Trend Analysis:** To study long-term changes or structural breaks in the data without seasonal noise.\n",
    "- **Regression Modeling:** When building models to explain or forecast the underlying process, removing seasonality can improve model accuracy and interpretability.\n",
    "- **Anomaly Detection:** Outliers and unusual events are easier to detect in seasonally adjusted data, as regular seasonal effects have been removed.\n",
    "- **Comparing Across Time:** Seasonally adjusted values allow for meaningful comparisons between different periods, unaffected by predictable seasonal swings.\n",
    "\n",
    "**Extracted seasonal components** are used when the focus is on understanding, visualizing, or modeling the seasonal patterns themselves. Use cases include:\n",
    "\n",
    "- **Seasonality Analysis:** To quantify and interpret the strength, timing, and nature of recurring cycles (e.g., daily, weekly, yearly).\n",
    "- **Feature Engineering:** Incorporating seasonal indices as features in machine learning models to capture periodic effects.\n",
    "- **Forecasting:** When future seasonal effects need to be explicitly modeled or projected, the extracted seasonal component can be added back to trend and residual forecasts.\n",
    "- **Business Insights:** Understanding when peaks and troughs occur (e.g., high electricity usage times) for operational planning or policy decisions.\n",
    "\n",
    "**Summary Table:**\n",
    "\n",
    "| Use Case                        | Use Seasonally Adjusted Data | Use Extracted Seasonal Component |\n",
    "|----------------------------------|:---------------------------:|:--------------------------------:|\n",
    "| Trend/Structural Analysis        | ✔️                          |                                  |\n",
    "| Anomaly/Outlier Detection        | ✔️                          |                                  |\n",
    "| Regression/ML Modeling           | ✔️                          |                                  |\n",
    "| Comparing Across Time Periods    | ✔️                          |                                  |\n",
    "| Understanding Seasonality        |                             | ✔️                               |\n",
    "| Feature Engineering (Seasonality)|                             | ✔️                               |\n",
    "| Forecasting with Seasonality     |                             | ✔️ (add to trend/residual)       |\n",
    "| Business/Operational Planning    |                             | ✔️                               |\n",
    "\n",
    "In practice, both seasonally adjusted data and extracted seasonal components are valuable—choose based on your analysis goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = res.observed\n",
    "trend = res.trend\n",
    "seasonal = res.seasonal\n",
    "seasonally_adjusted = observed - seasonal\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=data.get_column(time_), y=observed, mode=\"lines\", name=\"Observed\")\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data.get_column(time_),\n",
    "        y=seasonally_adjusted,\n",
    "        mode=\"lines\",\n",
    "        name=\"Seasonally Adjusted\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=time, y=trend, mode=\"lines\", name=\"Trend\"))\n",
    "fig.update_layout(\n",
    "    title=\"Observed vs Seasonally Adjusted\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        font=dict(size=12),\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2012-11-01\", \"2012-12-31\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51384b",
   "metadata": {},
   "source": [
    "## 5. STL: Seasonal-Trend Decomposition using LOESS\n",
    "\n",
    "STL is a robust, flexible method that can adapt to changes in trend and seasonality. It uses LOESS (locally weighted regression) for smoothing, which is more flexible than moving averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ed847",
   "metadata": {},
   "source": [
    "Unlike traditional decomposition methods, STL is highly adaptable and can handle complex time series data with varying seasonal patterns and trends.\n",
    "\n",
    "#### Mathematical Formulation of STL Decomposition\n",
    "\n",
    "Given a time series $y_t$, STL decomposes it into three components:\n",
    "\n",
    "$$\n",
    "y_t = T_t + S_t + R_t\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $T_t$ is the **trend** component,\n",
    "- $S_t$ is the **seasonal** component,\n",
    "- $R_t$ is the **residual** (remainder) component.\n",
    "\n",
    "**Trend Estimation:**  \n",
    "The trend component $T_t$ is estimated by applying LOESS (locally weighted regression) smoothing to the seasonally adjusted series:\n",
    "\n",
    "$$\n",
    "T_t = \\text{LOESS}(y_t - S_t)\n",
    "$$\n",
    "\n",
    "**Seasonality Estimation:**  \n",
    "The seasonal component $S_t$ is estimated by applying LOESS smoothing to the detrended series, typically using a window equal to the seasonal period:\n",
    "\n",
    "$$\n",
    "S_t = \\text{LOESS}(y_t - T_t)\n",
    "$$\n",
    "\n",
    "This process is performed iteratively, refining $T_t$ and $S_t$ at each step.\n",
    "\n",
    "**Residual Calculation:**  \n",
    "The residual is computed as:\n",
    "\n",
    "$$\n",
    "R_t = y_t - T_t - S_t\n",
    "$$\n",
    "\n",
    "#### Advantages of LOESS (Locally Estimated Scatterplot Smoothing)\n",
    "\n",
    "LOESS (or LOWESS) is a non-parametric regression method that fits simple models to localized subsets of the data:\n",
    "\n",
    "- **Adaptive Smoothing**: LOESS adapts the amount of smoothing based on the local structure of the data, allowing it to capture non-linear and varying trends.\n",
    "- **Handles Edges Better**: LOESS can provide trend estimates at the boundaries of the series, reducing edge effects.\n",
    "- **Robustness**: It can be made robust to outliers by using weighted regression.\n",
    "- **Flexibility**: LOESS does not assume a fixed window or linearity, making it suitable for complex, real-world time series.\n",
    "\n",
    "In summary, LOESS provides a more flexible and accurate trend estimation, especially when the underlying trend is non-linear or changes over time, whereas moving average is best suited for simple, stationary trends.\n",
    "\n",
    "For more information about LOESS, see:\n",
    "- [Lowess and Loess, Clearly Explained!!! (YouTube)](https://www.youtube.com/watch?v=Vf7oJ6z2LCc)\n",
    "- [Cleveland, W. S., & Devlin, S. J. (1988). \"Locally Weighted Regression: An Approach to Regression Analysis by Local Fitting.\" Journal of the American Statistical Association, 83(403), 596–610.](https://www.jstor.org/stable/2289282)\n",
    "- [Wikipedia: LOESS](https://en.wikipedia.org/wiki/Local_regression)\n",
    "- [Statsmodels documentation: Nonparametric regression](https://www.statsmodels.org/stable/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html)\n",
    "- [Rob J Hyndman: STL Decomposition](https://otexts.com/fpppy/nbs/03-decomposition.html#sec-stl)\n",
    "\n",
    "\n",
    "#### Advantages of STL\n",
    "1. **Adaptability**:\n",
    "    - STL can handle non-linear trends and varying seasonal patterns, making it suitable for complex time series data.\n",
    "\n",
    "3. **Robustness**:\n",
    "    - STL is robust to outliers and missing data, ensuring reliable decomposition in real-world scenarios.\n",
    "\n",
    " Note: STL assumes an additive model by default. While it can handle multiplicative models by transforming the data (e.g., log transformation), this requires additional preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce63ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stl = STL(\n",
    "    data.select(pl.col(target_).forward_fill()),\n",
    "    period=48,\n",
    ")\n",
    "res = stl.fit()\n",
    "fig = plot_decomposition(\n",
    "    time,\n",
    "    res.observed.to_numpy().squeeze(),\n",
    "    res.seasonal,\n",
    "    res.trend,\n",
    "    res.resid,\n",
    ")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2012-11-4\", \"2012-12-4\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1053a20c",
   "metadata": {},
   "source": [
    "### STL Interpretation\n",
    "\n",
    "- **Trend:** Still flat for this household.\n",
    "- **Seasonality:** STL adapts to changes in the seasonal pattern over time.\n",
    "- **Residuals:** Still some structure, suggesting more than one seasonal pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209d8d4",
   "metadata": {},
   "source": [
    "Besides seasonality analysis, STL has several other practical applications in time series analysis:\n",
    "\n",
    "1. **Forecasting**:  \n",
    "    STL is commonly used as a preprocessing step for forecasting models, allowing separate modeling of trend and seasonal effects to improve forecast accuracy. We will have a look at how to use STL, or rather MSTL to forecast in later chapter\n",
    "2. **Anomaly Detection**:  \n",
    "    By examining the residual component after removing trend and seasonality, STL helps to identify unusual patterns or outliers in the data.\n",
    "3. **Data Cleaning and Preprocessing**:  \n",
    "    Removing trend and seasonal components with STL can produce a stationary residual series, which is often required for further statistical analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0800a5",
   "metadata": {},
   "source": [
    "## 6. MSTL: Multiple Seasonal-Trend Decomposition using LOESS\n",
    "\n",
    "MSTL extends STL to handle multiple seasonalities (e.g., daily and weekly cycles). This is especially useful for electricity data, which often has both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b5f82",
   "metadata": {},
   "source": [
    "\n",
    "While STL is powerful for decomposing a time series into trend, seasonality, and residual components, it is limited to a **single seasonal period**. However, many real-world time series—such as electricity demand, web traffic, or retail sales—exhibit **multiple seasonal patterns** (e.g., daily and weekly cycles).\n",
    "\n",
    "#### What is MSTL?\n",
    "\n",
    "**MSTL** (Multiple Seasonal-Trend decomposition using LOESS) is an extension of STL that allows for the decomposition of time series with **multiple seasonalities**. MSTL iteratively applies STL to extract several seasonal components, each with its own period.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "Given a time series $y_t$, MSTL decomposes it as:\n",
    "\n",
    "$$\n",
    "y_t = T_t + S^{(1)}_t + S^{(2)}_t + \\cdots + S^{(K)}_t + R_t\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $T_t$ is the **trend** component,\n",
    "- $S^{(k)}_t$ is the $k$-th **seasonal** component (e.g., daily, weekly),\n",
    "- $R_t$ is the **remainder** (residual) component,\n",
    "- $K$ is the number of seasonalities.\n",
    "\n",
    "#### MSTL Algorithm (High-Level Steps)\n",
    "\n",
    "1. **Initial Trend Estimation**:  \n",
    "    Estimate the trend $T_t$ using LOESS smoothing.\n",
    "\n",
    "2. **Iterative Seasonal Extraction**:  \n",
    "    For each seasonal period $p_k$:\n",
    "    - Remove the current estimate of the trend and all other seasonal components from $y_t$.\n",
    "    - Apply STL to the detrended series to estimate $S^{(k)}_t$.\n",
    "\n",
    "3. **Update Trend**:  \n",
    "    After extracting all seasonal components, update the trend estimate using the seasonally adjusted series.\n",
    "\n",
    "4. **Repeat**:  \n",
    "    Iterate steps 2–3 until convergence.\n",
    "\n",
    "5. **Compute Residual**:  \n",
    "    $$\n",
    "    R_t = y_t - T_t - \\sum_{k=1}^K S^{(k)}_t\n",
    "    $$\n",
    "\n",
    "#### Example: Daily and Weekly Seasonality\n",
    "\n",
    "For a time series with both daily ($p_1 = 48$ for half-hourly data) and weekly ($p_2 = 336$) seasonality:\n",
    "\n",
    "$$\n",
    "y_t = T_t + S^{(\\text{daily})}_t + S^{(\\text{weekly})}_t + R_t\n",
    "$$\n",
    "\n",
    "#### Why MSTL?\n",
    "\n",
    "- **Captures Multiple Seasonal Patterns**:  \n",
    "  MSTL can simultaneously model daily, weekly, and even yearly cycles.\n",
    "- **Flexible and Robust**:  \n",
    "  Like STL, MSTL uses LOESS smoothing, making it robust to outliers and adaptable to non-linear trends.\n",
    "- **Improved Residuals**:  \n",
    "  By removing multiple seasonalities, the residual component $R_t$ is closer to white noise, improving downstream modeling and forecasting.\n",
    "\n",
    "#### References\n",
    "\n",
    "- Hyndman, R.J., Wang, E., & Laptev, N. (2021). [Forecasting with Multiple Seasonal Patterns: Introducing MSTL](https://robjhyndman.com/papers/mstl.pdf)\n",
    "- [Statsmodels MSTL Documentation](https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.MSTL.html)\n",
    "\n",
    "---\n",
    "\n",
    "In summary, MSTL generalizes STL to handle multiple seasonalities, making it a powerful tool for modern time series analysis where complex, overlapping cycles are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3dc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stl = MSTL(\n",
    "    data.select(pl.col(target_).forward_fill()),\n",
    "    periods=[48, 7 * 48],  # daily and weekly\n",
    ")\n",
    "res = stl.fit()\n",
    "fig = plot_decomposition(\n",
    "    data.get_column(time_),\n",
    "    res.observed,\n",
    "    {\"daily\": res.seasonal[:, 0], \"weekly\": res.seasonal[:, 1]},\n",
    "    res.trend,\n",
    "    res.resid,\n",
    ")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2012-11-4\", \"2012-12-4\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62040716",
   "metadata": {},
   "source": [
    "### MSTL Interpretation\n",
    "\n",
    "- **Daily seasonality:** Strong, as expected.\n",
    "- **Weekly seasonality:** Present but weaker.\n",
    "- **Trend:** Still flat.\n",
    "- **Residuals:** Now closer to white noise, meaning most structure is explained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb5b77",
   "metadata": {},
   "source": [
    "## 7. Quantifying Component Strength\n",
    "\n",
    "We can measure how much of the variation is explained by trend or seasonality using variance ratios. This gives an objective measure of component importance.\n",
    "\n",
    "### Measuring the Strength of Decomposed Components\n",
    "\n",
    "The strength of each decomposed component (trend, seasonality, and residual) can be quantified based on their variation. This provides an objective measure of how much each component contributes to the overall time series, as opposed to relying solely on visual inspection.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "1. **Trend Strength**:  \n",
    "    The strength of the trend component is defined as:\n",
    "\n",
    "    $$\n",
    "    \\text{Trend Strength} = \\max\\left(0, 1 - \\frac{\\text{Var}(R_t)}{\\text{Var}(T_t + R_t)}\\right)\n",
    "    $$\n",
    "\n",
    "    where:\n",
    "    - $R_t$ is the residual component,\n",
    "    - $T_t$ is the trend component,\n",
    "    - $\\text{Var}(\\cdot)$ denotes the variance.\n",
    "\n",
    "    This measures the proportion of variation explained by the trend relative to the combined trend and residual components.\n",
    "\n",
    "2. **Seasonal Strength**:  \n",
    "    For each seasonal component $S^{(k)}_t$, the strength is defined as:\n",
    "\n",
    "    $$\n",
    "    \\text{Seasonal Strength}^{(k)} = 1 - \\frac{\\text{Var}(R_t)}{\\text{Var}(S^{(k)}_t + R_t)}\n",
    "    $$\n",
    "\n",
    "    where:\n",
    "    - $S^{(k)}_t$ is the $k$-th seasonal component,\n",
    "    - $R_t$ is the residual component.\n",
    "\n",
    "    This measures the proportion of variation explained by the seasonal component relative to the combined seasonal and residual components.\n",
    "\n",
    "#### Advantages of Quantitative Measures\n",
    "\n",
    "1. **Objectivity**:  \n",
    "    Quantitative measures provide an objective way to assess the importance of each component, avoiding subjective biases that may arise from visual inspection of plots.\n",
    "\n",
    "2. **Comparability**:  \n",
    "    These measures allow for direct comparison of component strengths across different time series, enabling consistent evaluation.\n",
    "\n",
    "3. **Automation**:  \n",
    "    The strength measures can be computed programmatically, making them suitable for large-scale time series analysis where manual inspection is impractical.\n",
    "\n",
    "4. **Insight into Model Fit**:  \n",
    "    High residual variance relative to trend or seasonal components indicates that the decomposition may not fully capture the underlying structure of the time series, suggesting the need for model refinement.\n",
    "\n",
    "In summary, measuring the strength of decomposed components based on their variation provides a robust and scalable approach to understanding the contributions of trend, seasonality, and residuals in a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_strength(trend, seasonal, residual):\n",
    "    residual_var = residual.var()\n",
    "    trend_residual_var = (trend + residual).var()\n",
    "    trend_strength = max(0, 1 - residual_var / trend_residual_var)\n",
    "    if isinstance(seasonal, dict):\n",
    "        for name, component in seasonal.items():\n",
    "            seasonal_residual_var = (component + residual).var()\n",
    "            strength = max(0, 1 - residual_var / seasonal_residual_var)\n",
    "            print(f\"Seasonal strength ({name}): {strength:.4f}\")\n",
    "    elif hasattr(seasonal, \"ndim\") and seasonal.ndim > 1:\n",
    "        for i in range(seasonal.shape[1]):\n",
    "            seasonal_residual_var = (seasonal[:, i] + residual).var()\n",
    "            strength = max(0, 1 - residual_var / seasonal_residual_var)\n",
    "            print(f\"Seasonal strength (period {i + 1}): {strength:.4f}\")\n",
    "    else:\n",
    "        seasonal_residual_var = (seasonal + residual).var()\n",
    "        strength = max(0, 1 - residual_var / seasonal_residual_var)\n",
    "        print(f\"Seasonal strength: {strength:.4f}\")\n",
    "    print(f\"Trend strength: {trend_strength:.4f}\")\n",
    "    return trend_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = compute_strength(\n",
    "    res.trend, {\"daily\": res.seasonal[:, 0], \"weekly\": res.seasonal[:, 1]}, res.resid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0882592",
   "metadata": {},
   "source": [
    "- The daily seasonal component explains a substantial portion of the variation (strength ≈ 0.58), indicating strong daily patterns in electricity usage.\n",
    "- The weekly seasonal component is weaker (strength ≈ 0.22), suggesting some but less pronounced weekly cycles.\n",
    "- The trend component is relatively weak (strength ≈ 0.20), confirming that there is little long-term change in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04aabc",
   "metadata": {},
   "source": [
    "## 8. Automatic Feature Extraction with `tsfeatures`\n",
    "\n",
    "In addition to manual decomposition and strength calculations, you can automatically extract a variety of time series features—including STL-based features—using the [`tsfeatures`](https://github.com/Nixtla/tsfeatures) library. This library provides a convenient way to compute summary statistics and characteristics of time series, which are useful for exploratory analysis, feature engineering, and model selection.\n",
    "\n",
    "#### STL Features via `tsfeatures`\n",
    "\n",
    "The `tsfeatures` library includes the `stl_features` function, which computes several features based on STL decomposition, such as:\n",
    "\n",
    "- **trend_strength**: Quantifies the strength of the trend component.\n",
    "- **seasonal_strength**: Measures the strength of the seasonal component(s).\n",
    "- **spikiness**: Indicates the presence of sharp spikes in the residuals.\n",
    "- **linearity**: Measures the linearity of the trend.\n",
    "- **curvature**: Measures the curvature of the trend.\n",
    "- **seasonal_peak** and **seasonal_trough**: Identify the timing of seasonal peaks and troughs.\n",
    "\n",
    "These features provide a quantitative summary of the time series structure and can be used for time series classification, clustering, or as input features for forecasting models.\n",
    "\n",
    "#### Example Usage\n",
    "\n",
    "You can compute STL features for your time series as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfeatures(\n",
    "    data.select(pl.col(target_).forward_fill(), time_, id_).to_pandas(),\n",
    "    freq=48,\n",
    "    features=[stl_features],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa71e7f",
   "metadata": {},
   "source": [
    "## 9. Decomposition with Fourier Terms\n",
    "\n",
    "Fourier decomposition is a powerful approach for modeling and extracting seasonal patterns in time series data, especially when the seasonality is complex or involves multiple overlapping cycles. Instead of estimating the seasonal component by averaging or smoothing, Fourier decomposition represents seasonality as a sum of sine and cosine functions with different frequencies.\n",
    "\n",
    "#### How It Works\n",
    "\n",
    "- **Fourier Series Representation:**  \n",
    "    Any periodic function can be approximated by a sum of sine and cosine terms (Fourier series). For a time series with period $p$, the seasonal component $S_t$ can be modeled as:\n",
    "    $$\n",
    "    S_t = \\sum_{k=1}^{K} \\left[ a_k \\sin\\left(\\frac{2\\pi k t}{p}\\right) + b_k \\cos\\left(\\frac{2\\pi k t}{p}\\right) \\right]\n",
    "    $$\n",
    "    where $K$ is the number of harmonics (pairs of sine and cosine terms), and $a_k$, $b_k$ are coefficients estimated from the data.\n",
    "\n",
    "- **Multiple Seasonalities:**  \n",
    "    By including Fourier terms for different periods (e.g., daily and weekly), the model can capture multiple seasonal patterns simultaneously.\n",
    "\n",
    "- **Estimation:**  \n",
    "    The coefficients of the Fourier terms are typically estimated using linear regression, often after removing the trend from the series (detrending). This allows for flexible and efficient modeling of seasonality.\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- **Flexibility:**  Fourier terms can approximate a wide range of seasonal patterns, including those that are not strictly constant over time.\n",
    "- **Handles Multiple Seasonalities:**  Easily incorporates multiple seasonal cycles by adding terms for each relevant period.\n",
    "- **Smoothness:**  The resulting seasonal component is smooth and continuous, avoiding abrupt changes.\n",
    "\n",
    "#### Workflow\n",
    "\n",
    "1. **Detrend the Series:** Remove the trend component (e.g., using LOESS or moving average).\n",
    "2. **Generate Fourier Terms:** Create sine and cosine features for each seasonal period and harmonic.\n",
    "3. **Fit Regression:** Regress the detrended series on the Fourier terms to estimate the seasonal component.\n",
    "4. **Compute Residuals:** The remaining variation after removing trend and seasonality is the residual component.\n",
    "\n",
    "Fourier decomposition is widely used in modern forecasting models (such as Prophet) and is especially effective for time series with complex or multiple seasonal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0eda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.select(pl.col(target_).forward_fill()).to_numpy().squeeze()\n",
    "# 1. Extract trend using LOESS\n",
    "loess_trend = lowess(y, np.arange(len(y)), frac=0.1, return_sorted=False)\n",
    "# 2. Detrend the series\n",
    "detrended_loess = y - loess_trend\n",
    "# 3. Create Fourier terms for daily and weekly seasonality\n",
    "features = [\n",
    "    partial(fourier, season_length=48, k=10),\n",
    "    partial(fourier, season_length=48 * 7, k=5),\n",
    "]\n",
    "data_fourier, _ = pipeline(\n",
    "    data,\n",
    "    features=features,\n",
    "    freq=\"30m\",\n",
    "    h=1,\n",
    ")\n",
    "fourier_terms = data_fourier.select(pl.exclude([id_, time_, target_]))\n",
    "# 4. Fit regression on Fourier terms to estimate seasonality\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge_cv\", RidgeCV(fit_intercept=False)),\n",
    "    ]\n",
    ")\n",
    "model.fit(fourier_terms, detrended_loess)\n",
    "seasonal_fourier = model.predict(fourier_terms)\n",
    "# 5. Compute residuals\n",
    "residual_fourier = detrended_loess - seasonal_fourier\n",
    "# 6. Plot decomposition\n",
    "plot_decomposition(\n",
    "    time=time,\n",
    "    observed=y,\n",
    "    trend=loess_trend,\n",
    "    seasonal=seasonal_fourier,\n",
    "    resid=residual_fourier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = compute_strength(loess_trend, seasonal_fourier, residual_fourier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca78cb",
   "metadata": {},
   "source": [
    "- The strength output of the Fourier decomposition indicates that the seasonal component explains about 22% of the variation in the time series (seasonal strength ≈ 0.22), which suggests a weak but present seasonal pattern captured by the Fourier terms.\n",
    "- The trend strength is very low (≈ 0.03), meaning the trend component explains only a small fraction of the variation, and most of the structure in the series is not attributable to a long-term trend.\n",
    "- This aligns with the expectation for household electricity data, where seasonality may be present but the overall trend is minimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
